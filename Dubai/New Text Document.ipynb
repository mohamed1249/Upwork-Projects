{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning-based analysis to predict property sales transactions in Dubai, UAE Master of Science in Professional Studies: Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook goals is to:\n",
    "### execute machine learning strategies to use Machine learning-based analysis to predict property sales transactions in Dubai for 2023 based on 2019, 2020, and 2021 data, promoting customer acquisition and identification. The study goals are:\n",
    "\n",
    "* #### To use machine learning-based analysis to predict property sales transactions in Dubai for 2023 based on 2019, 2020, and 2021 data\n",
    "* #### To identify the criteria for decision-making by the UAE consumers and behavior when buying a property in Dubai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first Import aome of the libraries that we might need:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's take a look on a sample of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some information about the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 132688 record about transactions and 26 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset column names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's see some brief statistics on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interisting, but let's talk more about this statistics in the Analysis section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's check if there're any null values in the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fortunately there're not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much unique values in each column of the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Type column has only 1 uique value that is Sales, I don't think that this column would penfit any of our processes, let's drop it down from the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did transactions go through time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we need to create a dated dataset that has just the date and the number of transactions that occured in that date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can use this dated dataset in showing how the transactions goes through years and how its trend acts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of daily transactions has been increasing since 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the most frequent Transaction sub type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can find that Sell - Pre registraion is the  most frequent Transaction sub type, after it comes the Sale and delayed Sell, with that said, I wonder how have these three top sub types been going through the years? well, to figur out the answer of this question we need to create an area chart that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can see that Sale and Delayed Sell has been increasing in last year and half when Sell - Pre registration has been the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the most frequent Registration type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready Registration type has appeared in the data for 54% of all the transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does Registration type go through the years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Registration type has been also increasing in the last year and half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### were most of the transactions Free Hold or Non Free Hold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About 95% of the transaction were Free Hold transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent Usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About 96% of Usages were Residential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent Area?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Bay was the most frequent area of all the transaction, 7.7% of the transactions were in that area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent Property Type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit is the most frequent Property Type of all the transactions as 71% of the transactions were Unit Property Types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent Property Sub Type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat is the most frequent Property Sub Type as 64% of all the transactions were Flat Property Sub Type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount through time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distripution of amounts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although the average amount value is 1.75M, but the most frequent amount value was 1M and half of amounts values are below 1.26M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Size through time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distripution of Transaction Size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although the average Transaction Size value is 205, but the most frequent Transaction Size value was 161 and half of Transaction Sizes values are below 108."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property Size through time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distripution of Property Size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although the average Transaction Size value is 207, but the most frequent Transaction Size value was 45 and half of Transaction Sizes values are below 108."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most frequent Rooms Type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average - Smoothing :\n",
    "#### Acording to [Machine Learning Mastery](https://machinelearningmastery.com/moving-average-smoothing-for-time-series-forecasting-python/) -> Smoothing is a technique applied to time series to remove the fine-grained variation between time steps.\n",
    "\n",
    "#### The hope of smoothing is to remove noise and better expose the signal of the underlying causal processes. Moving averages are a simple and common type of smoothing used in time series analysis and time series forecasting.\n",
    "\n",
    "#### Calculating a moving average involves creating a new series where the values are comprised of the average of raw observations in the original time series.\n",
    "\n",
    "#### A moving average requires that you specify a window size called the window width. This defines the number of raw observations used to calculate the moving average value.\n",
    "\n",
    "#### The “moving” part in the moving average refers to the fact that the window defined by the window width is slid along the time series to calculate the average values in the new series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Since this is a Plotly plot, you can hide and show moving averages by a double click if it's so noisy for you to get a clearer look at every moving average.\n",
    "\n",
    "#### To get a deeper analysis of how the data goes let's use statsmodels.tsa.seasonal.seasonal_decompose which gives us a seasonal decomposition using moving averages.\n",
    "Check out [Seasonal decomposition](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality:\n",
    "#### according to [Kaggle](https://www.kaggle.com/code/ryanholbrook/seasonality) -> We say that a time series exhibits seasonality whenever there is a regular, periodic change in the mean of the series. Seasonal changes generally follow the clock and calendar -- repetitions over a day, a week, or a year are common. Seasonality is often driven by the cycles of the natural world over days and years or by conventions of social behavior surrounding dates and times.\n",
    "#### Now let's use the following very helpful functions that was provided by Kaggle's experts to check whether our data is seasonal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the previous plots (especially the last one) we can find that our time series here do has a double-annual seasonality.\n",
    "\n",
    "## Stationary:\n",
    "#### According to [otexts.com](https://otexts.com/fpp2/stationarity.html) ->\n",
    "#### A stationary time series is one whose properties do not depend on the time at which the series is observed.14 Thus, time series with trends, or with seasonality, are not stationary — the trend and seasonality will affect the value of the time series at different times. On the other hand, a white noise series is stationary — it does not matter when you observe it, it should look much the same at any point in time.\n",
    "#### Now thanks to [ABHISHEKMAMIDI](https://www.kaggle.com/code/abhishekmamidi/time-series-preprocessing-to-modelling/notebook) who has made the following function that can check time series stationarity we can check whether our time series is stationary or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the [p-value](https://machinelearningmastery.com/time-series-data-stationary-python/) is more than 0.05, We can say that our time series here is not stationary, but what can we do about that?\n",
    "#### Well one way to make a non-stationary time series stationary is by [Differencing](https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again after looking at the p-value here which is very close to 0 (less than 0.05), our time series has become stationary and ready to be forecasted.\n",
    "## Autocorrelation and partial autocorrelation\n",
    "\n",
    "#### acording to [IBM](https://www.ibm.com/docs/en/spss-modeler/saas?topic=data-autocorrelation-partial-autocorrelation-functions) -> Autocorrelation and partial autocorrelation are measures of association between current and past series values and indicate which past series values are most useful in predicting future values. With this knowledge, you can determine the order of processes in an ARIMA model. More specifically,\n",
    "#### * Autocorrelation function (ACF). At lag k, this is the correlation between series values that are k intervals apart.\n",
    "#### * Partial autocorrelation function (PACF). At lag k, this is the correlation between series values that are k intervals apart, accounting for the values of the intervals between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From that previos plots we can find that all lags under 30 can be helpful in predicting the future of this time series, let's use them in our model as the p value, the d value will be 0 as we've already diffrentiate the time series.\n",
    "For more information you can click [here](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's create a function that give us a real forecast of property sales transactions in Dubai for the next year!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this graph of forecasting the property sales transactions in Dubai, we can find that the sales are going up, although it's not a good approach to count on more than 2 weeks' forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: clustering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'No. of Buyer',\t'No. of Seller' are not correlated with the other column I'll remove them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's only one row that has clustered in a single cluster, fore sure it's an outlier, I'll remove it frome the data so that remains only 6 clusters (groups of the daya)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster 1:\n",
    "- there were 12K transactions\n",
    "- the average Amount was 5.25M\n",
    "- the average Transaction Size was 1.5K\n",
    "- the average Property Size was 1.15K\n",
    "- all was a Free Hold\n",
    "- all was Residential Usage\n",
    "- all was Land Property Type\n",
    "- all was Ready Registration type exept 1 transaction was Off-Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster 2:\n",
    "- there were 48K transactions\n",
    "- the average Amount was 1.6M\n",
    "- the average Transaction Size was 84\n",
    "- the average Property Size was 83\n",
    "- all was a Free Hold\n",
    "- all was Residential Usage\n",
    "- all was Unit Property Type\n",
    "- all was Off-Plan Registration type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster 3:\n",
    "- there were 5K transactions\n",
    "- the average Amount was 8.8M\n",
    "- the average Transaction Size was 1935\n",
    "- the average Property Size was 1986\n",
    "- there were 4321 transactions that were a Free Hold, and other 783 Non Free Hold \n",
    "- all was Commercial Usage\n",
    "- all was Land Property Type\n",
    "- all was Ready Registration type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster 4:\n",
    "- there were 45K transactions\n",
    "- the average Amount was 1.4M\n",
    "- the average Transaction Size was 120\n",
    "- the average Property Size was 121\n",
    "- all was a Free Hold\n",
    "- all was Residential Usage\n",
    "- all was Unit Property Type\n",
    "- all was Ready Registration type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster 5:\n",
    "- there were 5.5K transactions\n",
    "- the average Amount was 3.25M\n",
    "- the average Transaction Size was 1.2K\n",
    "- the average Property Size was 1.3K\n",
    "- all was Non Free Hold\n",
    "- all was Residential Usage\n",
    "- there were 2533 Land Property Type, 2319 Unit and 688 Building.\n",
    "- there were 4944 Ready Registration type, and other 596 Off-Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cluster 6:\n",
    "- there were 17.6K transactions\n",
    "- the average Amount was 1.9M\n",
    "- the average Transaction Size was 219\n",
    "- the average Property Size was 220\n",
    "- all was a Free Hold\n",
    "- all was Residential Usage\n",
    "- all was Building Property Type\n",
    "- There were 12491 Off-Plan Registration type and 5153 Ready"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "346812b7c4f63123021a0011a7ad9c451703c57cd6c6827f3f726952f0a6ac21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
