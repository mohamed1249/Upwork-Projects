{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bc1b5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Artificial Neural Networks 1 - The Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92b500",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This week's problem:\n",
    "## Train a simple Neural Network to distinguish between two different types of Iris flowers\n",
    "\n",
    "### Description\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/iris_measurements.png\" width=\"200\" align=\"center\">\n",
    "    <br/><a align=\"center\" href=\"https://kedro.readthedocs.io/en/stable/02_get_started/05_example_project.html\">Image taken from Kedro</a>\n",
    "</div>\n",
    "\n",
    "Based on some measurements about iris flowers, such as sepal length/width, we would like to create an algorithm to distinguish their class, which in our case can be either \"Iris-setosa\" or \"Iris-versicolor\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678c97e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We assume that there is no information to guide us, other than some examples of measurements and the corresponding class these measurements belong to. For example:\n",
    "\n",
    "| sepal length (cm) | sepal width (cm) | petal length (cm) | petal width (cm) |      class      |\n",
    "|-------------------|------------------|-------------------|------------------|-----------------|\n",
    "|        4.9        |       3.0        |        1.4        |        0.2       |   Iris setosa   |\n",
    "|        5.9        |       3.0        |        4.2        |        1.5       | Iris versicolor |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf115e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The dataset\n",
    "\n",
    "The full dataset for this week's problem can be found by following [this link](https://archive.ics.uci.edu/ml/datasets/iris). In the accompanying file `iris_partial.csv`, a part of the dataset is included in `.csv` (comma separated values) format. The file can be red and visualised using `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef1b80c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length  sepal width  petal length  petal width            class\n",
       "0            5.1          3.5           1.4          0.2      Iris-setosa\n",
       "1            4.9          3.0           1.4          0.2      Iris-setosa\n",
       "2            4.7          3.2           1.3          0.2      Iris-setosa\n",
       "3            4.6          3.1           1.5          0.2      Iris-setosa\n",
       "4            5.0          3.6           1.4          0.2      Iris-setosa\n",
       "..           ...          ...           ...          ...              ...\n",
       "95           5.7          3.0           4.2          1.2  Iris-versicolor\n",
       "96           5.7          2.9           4.2          1.3  Iris-versicolor\n",
       "97           6.2          2.9           4.3          1.3  Iris-versicolor\n",
       "98           5.1          2.5           3.0          1.1  Iris-versicolor\n",
       "99           5.7          2.8           4.1          1.3  Iris-versicolor\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #import pandas module\n",
    "\n",
    "#pd.set_option('display.max_rows', None) #uncomment this line to view full dataset\n",
    "\n",
    "irisDf = pd.read_csv(\"iris_partial.csv\") #read the file containing the data\n",
    "\n",
    "irisDf #visualise data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed8d1c-0769-4733-b467-2b93cc01f4f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relevance\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/relevance.png\" width=\"900\" align=\"center\">\n",
    "    <br/><a align=\"center\" href=\"https://www.qualitymag.com/articles/96664-how-ai-and-machine-vision-impact-vision-robotics\">Image taken from Quality magazine</a>\n",
    "</div>\n",
    "\n",
    "The problem described above might initially seem unrelated to industrial applications. However, from a mathematical/methodological point of view, it is very similar to several important applications. For instance, some of the algorithms used to distinguish between different types of flowers, can also be used to distinguish between pictures of different objects, a task needed to guide industrial robots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86093eb1-fc70-4dbb-b927-de06db2d0087",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "To solve todays problem, we will employ Machine Learning (ML) techniques. So before getting into the specifics, let's start with some general information.\n",
    "\n",
    "[Definition](http://www.cs.cmu.edu/~tom/mlbook.html):\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Machine Learning is the study of computer algorithms that improve automatically through experience.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28188ee0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Although the range of potential applications is vast, most machine learning methods can be thought of as function approximators, i.e. methods aiming at constructing models that approximate functions. However, the structure of these models, as well as the ways in which they can be reconfigured to approximate different functions, vary widely among different methods.\n",
    "\n",
    "In the following, some definitions are given, which should illustrate how these methods are relevant for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a2b82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Typical Machine Learning Tasks\n",
    "\n",
    "Machine learning can be used for a variety of tasks, two of the most common ones are:\n",
    "\n",
    "<table align=\"center\">\n",
    "  <tr>\n",
    "     <td>\n",
    "        <img src=\"./Figures/Regression.png\" width=\"450\">\n",
    "         <br/><a align=\"center\">Regression</a>\n",
    "     </td>\n",
    "     <td>\n",
    "        <img src=\"./Figures/Classification.png\" width=\"450\">\n",
    "        <br/><a align=\"center\">Classification</a>\n",
    "     </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "+ **Regression**: this is the task of approximating the relationship between a dependent variable $\\mathbf{y}$ and an independent variables $\\mathbf{x}$. For example, given a company's sales over the last months, predict the sales in the following months. In this case, time is the independent variable and sales are the dependent one.\n",
    "+ **Classification**:this involves assigning inputs to one of $k$ categories. For example, specify whether a given image depicts a bus, an airplane, or a ship. The special case where the number of categories is two, is refered to as **binary classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa014123",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Both of the above tasks, can be viewed as function approximation:\n",
    "    <li> In the case of regression, we try to find a function $f$ that maps the inputs $\\mathbf{x}$ to the outputs $\\mathbf{y}$: $\\mathbf{y}=f\\left( \\mathbf{x} \\right)$</li>\n",
    "    <li> In the case of classification, the task is almost the same, the different being that the output is not a real number, or set of real numbers as in the regression case. Rather, it is an integer number, assuming values in the range $[1,k]$, where $k$ is the number of classes. </li>\n",
    "</div>\n",
    "\n",
    "Our problem for today is a **classification** problem, and since we are only considering two categories of flowers, it can be further categorised as **binary classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf25e4-81f5-4b19-ac52-c2568812a8f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Machine Learning Approaches\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/supervised_unsupervised.png\" width=\"1200\" align=\"center\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a1025",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As mentioned above, machine learning algorithms learn through experience. In most cases, experience is provided in terms of **data** with examples relevant to the task to be performed. Depending on the exact form of the provided data, two models of learning can be defined:\n",
    "\n",
    "+ **Supervised learning**: in this case, the provided data contains examples of inputs as well as outputs, also termed **labels**. For instance, for the problem of classifying images of means of transport, data would consist of a set of images of buses, airplanes etc. Labels, would consist of the category in which each each image belongs to. \n",
    "+ **Unsupervised learning**: in this case, only inputs are provided as data and the algorithm should discover patterns in this data. For example, given usage data of a large group of users of an online platform, an algorithm might be employed to subdivide them to groups according to their preferences and, based on that, provide suggestions to individual users.\n",
    "\n",
    "Today's problem is a supervised learning problem, where data is provided in terms of the folwer measurements and labels are provided in terms of the flower class. While, in our case, labels are provided in terms of class names, they can be easily converted to numerical values, for instance 0 for 'Iris-setosa' and 1 for 'Iris-versicolor'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a58fc5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Artificial Neural Networks\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/artificial_intelligence.jpg\" width=\"800\" align=\"center\">\n",
    "    <br/><a align=\"center\" href=\"https://www.intelligenttransport.com/transport-articles/131855/artificial-intelligence-public-transport/\">Image taken from Intelligent Transport</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aadcae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As mentioned above, most machine learning methods aim at constructing function approximators. Biological neural networks, such as the human brain can also be viewed as a function approximators, receiving inputs, such as signals from sensory neurons, and transforming them into outputs, such as signals to motor neurons connected to muscles. More importantly, biological neural networks have the ability to adjust to different conditions and improve their performance, a property that is desirable also for machine learning methods.\n",
    "\n",
    "Artificial Neural Networks (ANNs) are machine learning systems, whose structure is inspired from biological neural networks, in an attempt to mimic the above features. Today's problem can be solved using a very simple type of neural network, which we will describe in detail in what follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510f95c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Single Layer Perceptron\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/Components_of_neuron.jpg\" width=\"800\" align=\"center\">\n",
    "    <br/><a align=\"center\" href=\"https://opentextbc.ca/introductiontopsychology/chapter/3-1-the-neuron-is-the-building-block-of-the-nervous-system/\">Components of a neuron by Jennifer Walinga</a>\n",
    "</div>\n",
    "\n",
    "The Single Layer Perceptron (SLP) is an elementary model of a neuron, and probably the simplest possible neural network. Similarly to a neuron, it receives different input signals and transforms them to a single output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d2b50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Elements of the SLP\n",
    "\n",
    "A SLP is composed of layers, including the following elements.\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/slp.png\" width=\"700\" align=\"center\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496af3a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Inputs\n",
    "\n",
    "The first element of the SLP are the input nodes, containing the multi-dimensional input $x_1, x_2, \\dots, x_n$ of the perceptron. These correspond to the input signals reaching a biological neuron coming, for instance, from sensory neurons.\n",
    "\n",
    "##### Weights, summing and bias\n",
    "\n",
    "Each input node is connected to a node of the next layer, where all inputs $x_i$ are weighted by corresponding weights $w_i$, and summed, yelding the weighted sum: $\\Sigma w_i x_i$. An additional value, termed bias $b$, is then added to the result.\n",
    "\n",
    "In the above operations, high or low weights could be interpreted as strong or weak connections between the input nodes and the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6ad8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Activation function\n",
    "\n",
    "As a last operation performed by the SLP, the result of the above operations is used as input for a so called activation function. In the following table, examples of commonly used activation functions are given.\n",
    "\n",
    "|Activation function|               Expression                   |                                 Graph                      |\n",
    "|-------------------|--------------------------------------------|------------------------------------------------------------|\n",
    "|       Linear      |          $$ f\\left( x \\right) = x $$       |<img src=\"./Figures/linear.png\" width=\"300\" align=\"center\"> |\n",
    "|       Heaviside   |$$ f\\left( x \\right) = \\left\\{\\begin{array}{c} 0, \\qquad x < 0 \\\\ 1, \\qquad x \\geq 0 \\end{array}\\right.$$|<img src=\"./Figures/heaviside.png\" width=\"300\" align=\"center\">|\n",
    "|        Sigmoid    |$$ f\\left( x \\right)=\\frac{1}{1+e^{-a x}} $$|<img src=\"./Figures/sigmoid.png\" width=\"300\" align=\"center\">|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976c429",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The linear activation function essentially corresponds to no activation function. The remaining functions, result to either 0 or 1, with or without a transition zone in between. This aims at imitating the firing of neurons depending on whether the input signals are strong enough.\n",
    "\n",
    "Traditionally, SLPs use the Heaviside activation function, however in what follows, we will use the sigmoid, since it is more representative of the general case. Modern neural networks employ different activation functions, which we will explore in the next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038fcf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Output\n",
    "\n",
    "Depending on the activation function used, the output of the SLP might be unbounded, or within the interval $[ 0,1 ]$. In the first case, the output could be used for regression, while in the second it might be more suitable for binary classification. For example, using a simple threshold, binary outputs can be obtained as:\n",
    "\n",
    "$$\\text{output} = \\left\\{\\begin{array}{c }\n",
    "                         0, \\qquad y < \\text{threshold}   \\\\\n",
    "                         1  \\qquad y \\geq \\text{threshold} \\end{array}\\right.$$\n",
    "\n",
    "with 0.5 a common value for the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7678b62-02ed-4b57-8b98-da551627bacb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Mathematical expression\n",
    "\n",
    "The operations performed by individual elements can be compactly described by a simple mathematical expression:\n",
    "\n",
    "$ y = f\\left( \\Sigma_{i=1}^n w_i x_i + b \\right)$\n",
    "\n",
    "with $f$ being one of the activation functions described above.\n",
    "\n",
    "The inputs and weights in the above expression can be written as vectors:\n",
    "\n",
    "$$\\mathbf{x} = \\left[\t\n",
    "\t\\begin{array}{c }\n",
    "    \tx_1   \\\\\n",
    "     \tx_2   \\\\\n",
    "        \\vdots \\\\\n",
    "        x_n  \\end{array}\\right]$$\n",
    "        \n",
    "$$\\mathbf{w} = \\left[\t\n",
    "\t\\begin{array}{c }\n",
    "    \tw_1   \\\\\n",
    "     \tw_2   \\\\\n",
    "        \\vdots \\\\\n",
    "        w_n  \\end{array}\\right]$$\n",
    "\n",
    "Then, the mathematical expression describing the SLP can be re-written as:\n",
    "\n",
    "$$ y = f\\left( \\mathbf{x}^T \\mathbf{w} + b \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce867d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Geometrical interpretation\n",
    "\n",
    "##### 1D case\n",
    "\n",
    "A geometrical interpretation of the elements of the SLP can provide some further insight. For example, let's consider a SLP with a single input $x$ and a linear activation function. The output is given by:\n",
    "\n",
    "$$y = w x + b$$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The SLP approximates functions with lines! Thus, it should be equivalent to linear regression.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74784c-3f92-4578-a10b-c10d31107b26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### 2D and higher dimensional case\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/linearly_separable.png\" width=\"500\" align=\"center\">\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "Next let's consider a SLP with a two dimentional input and and activation function. The output is:\n",
    "\n",
    "$$ y = f\\left( w_1 x_1 + w_2 x_2 + b \\right) = f\\left( \\mathbf{x}^T \\mathbf{w} + b \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04621987",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The expression $\\mathbf{x}^T \\mathbf{w} + b$ is the equation of a line in the two dimensional plane. It will yield positive values for points on one side of the line, negative values for points on the other side, and zero for points on the line. Applying an activation function on the result of this epression will result in values close to zero for points on one side of the line, values close to one for points on the other side of the line and 0.5 for points on the line.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The SLP essentially defines a line in the two dimensional plane and assigns points on each side of the line to a different class! Similarly, for higher dimensional inputs, the SLP defines planes and hyperplanes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f2dd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Let's illustrate the above concepts using an example. Consider the following points in the two-dimensional plane, labeled with 0 or 1:\n",
    "\n",
    "|   $$x_1$$   |   $$x_2$$   | label |\n",
    "|-------------|-------------|-------|\n",
    "| 8.51238062  | -8.76864249 |   0   |\n",
    "| 6.9330325   | -9.29863235 |   0   |\n",
    "| -2.06950209 | -9.59023795 |   0   |\n",
    "| 6.86539779  | -4.88532313 |   0   |\n",
    "| 9.36931477  | -1.94525181 |   0   |\n",
    "| 9.60978718  | -1.69978847 |   0   |\n",
    "| 2.02824178  | -4.47718114 |   0   |\n",
    "|-3.38539501  | -7.1189215  |   0   |\n",
    "| 5.78223496  | -2.34854873 |   0   |\n",
    "| 6.52367412  | -1.08966775 |   0   |\n",
    "| -1.18064469 | 3.93168945  |   1   |\n",
    "|  2.55102216 | 7.07542036  |   1   |\n",
    "| -6.25752382 | 3.39005381  |   1   |\n",
    "| -2.96953921 | 6.03485266  |   1   |\n",
    "| -5.59346953 | 6.07068803  |   1   |\n",
    "| -9.59644732 | 4.9616529   |   1   |\n",
    "| -5.85326519 | 7.07350523  |   1   |\n",
    "| -4.98872308 | 7.76378415  |   1   |\n",
    "| -7.60106264 | 7.0364926   |   1   |\n",
    "| -9.16771375 | 7.96643062  |   1   |\n",
    "\n",
    "They can be represented as numpy arrays and visualised as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1895499",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import numpy and matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#define arrays with input data and labels\n",
    "x = np.array([[ 8.51238062,  6.9330325 , -2.06950209,  6.86539779,  9.36931477,\n",
    "         9.60978718,  2.02824178, -3.38539501,  5.78223496,  6.52367412,\n",
    "        -1.18064469,  2.55102216, -6.25752382, -2.96953921, -5.59346953,\n",
    "        -9.59644732, -5.85326519, -4.98872308, -7.60106264, -9.16771375],\n",
    "       [-8.76864249, -9.29863235, -9.59023795, -4.88532313, -1.94525181,\n",
    "        -1.69978847, -4.47718114, -7.1189215 , -2.34854873, -1.08966775,\n",
    "         3.93168945,  7.07542036,  3.39005381,  6.03485266,  6.07068803,\n",
    "         4.9616529 ,  7.07350523,  7.76378415,  7.0364926 ,  7.96643062]])\n",
    "\n",
    "labels = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "#plot the first 10 points (label 0) with red color and the remaining 10 (label 1) with blue\n",
    "plt.plot(x[0,1:10],x[1,1:10],'.b')\n",
    "plt.plot(x[0,10:],x[1,10:],'.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fcd1be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Weights and bias\n",
    "\n",
    "Next, consider a SLP with a sigmoid activation function and the following weights/bias:\n",
    "\n",
    "$$w_1 = -0.5, \\ w_2 = 1.0 \\\\\n",
    "b = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7670863",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Point with label 0\n",
    "\n",
    "Applying the weights and bias to the first point, with coordinates $\\left(8.51238062, -8.76864249  \\right)$, will yield:\n",
    "\n",
    "$$w_1 y_1 + w_2 y_2 +b = -0.5 \\times 8.51238062 + 1.0 \\times \\left( -8.76864249 \\right) + 0 = -13.0248328$$\n",
    "\n",
    "Applying the sigmoid activation function:\n",
    "\n",
    "$$\\dfrac{1}{1+e^{-\\left( -13.0248328 \\right)}} = 2.20488544 \\times 10^{-6}$$\n",
    "\n",
    "Applying a 0.5 threshold to the result yields the value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9c184",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Point with label 1\n",
    "\n",
    "Similarly for a point with coordinates $\\left(-1.18064469, 3.93168945  \\right)$ and label 1:\n",
    "\n",
    "$$w_1 y_1 + w_2 y_2 +b = -0.5 \\times \\left( -1.18064469 \\right)+ 1.0 \\times 3.93168945 + 0 = 4.5220118$$\n",
    "\n",
    "$$\\dfrac{1}{1+e^{-4.5220118}} = 0.989249686$$\n",
    "\n",
    "A 0.5 threshold yields a value of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c840085",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation for all points using `numpy`\n",
    "\n",
    "The above operations can be applied to all points using numpy and matrix operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d24f26f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False  True  True\n",
      "  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#define array with weights and bias\n",
    "w = np.array([-0.5,1.0])\n",
    "b = 0\n",
    "\n",
    "#compute the weighted sum as a matrix operation\n",
    "weightedSum = np.matmul(x.transpose(),w)+b\n",
    "\n",
    "#use numpy to compute the value of the activation function\n",
    "y = 1/(1+np.exp(-weightedSum))\n",
    "\n",
    "#convert the result to binary format by applying a 0.t threshold\n",
    "yBinary = y>0.5\n",
    "\n",
    "#print result\n",
    "print(yBinary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdd557",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The SLP can correctly predict all the labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6f086",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Geometrical representation of the SLP\n",
    "\n",
    "Rewriting the equation of the line defined by the SLP yields:\n",
    "\n",
    "$$w_1 x_1 + w_2 x_2 + b=0 \\rightarrow x_2 = - \\dfrac{w_1}{w_2} x_1 - b$$\n",
    "\n",
    "Then the line can be plotted along with the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce69b565",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjXElEQVR4nO3de3xU9Z3/8deHhCCC3O8gKAqoqIsYo1G0QSrLzaUgKCgkrfWHsrJLddctleqjW+3DWkVKtxaklYczCEQoFVgBobIbvGwsARYVBAsoLCEBgcrNEELC9/fHDDSNkxBIzpxJzvv5eOQxZ873ZOaT71w++V7O95hzDhERCa4GfgcgIiL+UiIQEQk4JQIRkYBTIhARCTglAhGRgEv2O4AL0aZNG3fZZZf5HYaISJ2yYcOGg865thX318lEcNlll7F+/Xq/wxARqVPMbHes/eoaEhEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgFMiOJfcXHjuucitiEg9VCfPI4ib3FwYMABKSiAlBdasgfR0v6MSEalVahFUJScnkgTKyiK3OTl+RyQiUuuUCKqSkRFpCSQlRW4zMvyOKL7ULSYSCJ52DZlZL+CNcru6A087535Z7pgMYCnwRXTXH5xzP/UyrmpLT490B+XkRJJAkLqF1C0mEhieJgLn3GdAHwAzSwL2Am/GOPQ959wwL2O5YOnpwfwCjNUtFsR6EAmAeHYNDQB2OudiLnokCSbo3WIiARLPWUNjgAWVlKWb2UdAAfCvzrktFQ8wswnABICuXbt6FqREBblbTCRgzDnn/ZOYpRD5ku/tnNtfoawZcNo5d9zMhgAznHM9qnq81NRUp2WoRUTOj5ltcM6lVtwfr66hwcDGikkAwDl31Dl3PLq9AmhoZm3iFJeISODFKxGMpZJuITPrYGYW3U6LxnQoTnEFh6aCBptef6mC52MEZnYxcBfwcLl9jwA452YBo4CJZlYKnADGuHj0VyWK3Fzv++E1FTTY9PrLOXieCJxzRUDrCvtmldv+NfBrr+NISPH6gGoqaLDp9Zdz0JnFforXEhaaChpsev3lHLTonJ/OfEDPtAi8+oBqKmiw6fWXc4jL9NHaVq+mj8ZjjEBEhMqnj6pF4LegLmEhIglDYwQiIgGnRCAiEnBKBCIiAadEICIScEoEIiIBp0QQVIm+9kyixydSj2j6aBAl+toziR6fSD2jFkEQxWtpiwuV6PGJ1DNKBEGU6GvPJHp8IvWMuoaCKNHXnkn0+ETqGa01JCISEH5fqlJERBKUEoGISMApEYiIBJwSgYhIwHmeCMxsl5l9YmabzOwbI7wW8Ssz22FmH5tZX69jEhGRv4rX9NH+zrmDlZQNBnpEf24GZkZvRUQkDhKha2g4EHYRHwItzKxjXCPQujYiEmDxaBE4YLWZOeAV59zsCuWdgT3l7udH9xXGITatayMiCe2rr77ijTfeoHXr1owePdqT54hHi+A251xfIl1Aj5rZHRXKLcbvfOMsNzObYGbrzWz9gQMHai86rWsjIgnm1KlTvPXWW4wePZoOHTowceJEfv/733v2fJ4nAudcQfT2S+BNIK3CIfnApeXudwEKYjzObOdcqnMutW3btrUXoNa1EZEEM3bsWO6++27Wrl3LI488woYNG8jOzvbs+TxNBGbWxMwuObMNDAQ2VzhsGZAZnT10C3DEORefbiH467o2zzyjbiERibt9+/Yxbdo0+vbty759+wCYNGkSS5cuZe/evcyYMYO+fftiFqvzpHZ4PUbQHngz+gckA/Odc2+b2SMAzrlZwApgCLADKAK+53FM35SergQgInFTXFzM0qVLCYVCrFq1itOnT5OWlsa+ffvo0KEDGXHumdCicyIiceCc4/Dhw7Rs2ZI9e/bQrVs3OnfuzPjx48nMzOSqq67yPIbKFp3TMtQiIh7atWsX4XCYcDhMz549WbFiBZdeeil5eXn06dOHpKQkv0NUIhAR8cLSpUuZPn06a9euBaB///7cf//9Z8tvvPFGv0L7BiUCEZFaUFZWxn/913/Rr18/GjduzKeffkpBQQHPPvss48aNo1u3bn6HWCmNEYiI1MDWrVsJhUK8/vrr7N27l+zsbO677z5KSkpo2LChp7N9zpfGCEREatGhQ4cYPHgweXl5JCUlMXjwYKZPn87dd98NQEpKis8RVp8SgUhurq6PLOdUUlLCypUrKSws5JFHHqFVq1Z069aNsWPHcv/999O+fXu/Q7xg6hqSYNNaU1IF5xwbNmwgHA6zYMECDh48SM+ePdm6dSsNGiTCmp3nR9csFolFa01JFZ599lluuukmZs+ezZ133sny5cvZsmVLnUwCVVHXkATbmbWmzrQItNZUYBUVFbFkyRJCoRBPPfUU/fr1Y+TIkbRv357Ro0fTsmVLv0P0jBKBBNuZtaY0RhBIzjnee+89QqEQixYt4tixY3Tr1o1Dhw4B0Lt3b3r37u1zlN5TIhDRWlOBc/z4cZo2bcqpU6cYOXIkJ0+eZNSoUWRlZXHHHXfUu66fc1EiqG80A0YkpiNHjrBo0SJCoRAFBQVs376dlJQUVq5cyTXXXEOTJk38DtE3SgT1iWbAiHzDhg0bePHFF1myZAnFxcVcddVVPPTQQ5w6dYpGjRpx0003+R2i75QI6pNYM2CUCCSANm/eTOvWrenYsSP5+fmsXr2a73//+2RmZnLTTTcl1Nm+iSBYHWH1na62JgF24MABZsyYwY033sh1113HzJkzARg6dCgFBQX8+te/Ji0tTUkgBrUI6hPNgJEAcs5x7733smTJEkpLS+nbty8zZsxg7NixACQnJ5OcrK+6qqh26hvNgJF6zjnHunXrePfdd3niiScwM9q1a8djjz1GZmYm1157rd8h1jlaYkJE6oT8/Hzmzp1LOBxm27ZtNG7cmN27d9O2bVu/Q6sztMSEiNRZS5cupWvXrjz55JO0bduW3/72txQWFioJ1BJ1DYlIQjl9+jRr164lHA7Tv39/MjMzuf3223n66acZP348V1xxhd8h1jueJgIzuxQIAx2A08Bs59yMCsdkAEuBL6K7/uCc+6mXcYlI4tm+fTvhcJi5c+eye/duLrnkEq655hoAWrVqxU9+8hN/A6zHvG4RlAL/4pzbaGaXABvM7I/OuU8rHPeec26Yx7GISIIpLi7moosuAiAzM5N169Zx11138dxzzzF8+HAuvvhinyMMBk8TgXOuECiMbh8zs61AZ6BiIhCRgDh16hSrV68mFAqxatUqdu3aRcuWLZk5cybt2rWjU6dOfocYOHEbIzCzy4AbgD/FKE43s4+AAuBfnXNbYvz+BGACQNeuXT2MVES8sGfPHqZPn868efP48ssvad26NVlZWZw8eRKAPn36+BtggMVl+qiZNQXWAj9zzv2hQlkz4LRz7riZDQFmOOd6VPV4mj4qUjfs37+fY8eOceWVV/LnP/+Z6667jmHDhjF+/HiGDBlSp67rWx/4dvF6M2sILAbmVUwCAM65o+W2V5jZb8ysjXPuoNexiUjtKy4uZtmyZYTDYd5++21GjBjBokWL6NmzJ19++SXNmzf3O0SpwOtZQwa8Cmx1zr1UyTEdgP3OOWdmaUTObTjkZVwi4o1///d/55e//CWHDx+mc+fOPPHEE2RlZZ0tVxJITF63CG4DxgOfmNmm6L4nga4AzrlZwChgopmVAieAMa4unu4sEkC7d+8mOzubxx9/nIYNG5KSksKwYcPIysqif//+JCUl+R2iVIOWmBCR83Ls2DEWL15MKBQiJycHgHfffZfbb7/d38DknHwbIxCR+mPbtm3ceOONFBUVceWVV/LTn/6U8ePHc9lll/kdmtSAEoGIVGrbtm2EQiGaNm3K1KlT6dmzJ5MmTWL48OGkp6drbf96QolARP7GoUOHyM7OJhwOs27dOpKSkhg3bhwADRo04Pnnn/c5QqltWn1URDh16hRnxgunTJnCpEmTKC4uZtq0aeTn5/Paa6/5G6B4SolAJKCcc2zcuJHJkyfTqVMnNm7cCMATTzzB//7v//LRRx/x+OOP06FDB58jFa+pa0gkYI4fP87MmTMJhUJs2bKFlJQUhg8fTsOGDQHo2bOnzxFKvKlFIBIAJ06cYNu2bUCkn//ZZ5+lWbNmzJw5k3379rFw4UKuv/56n6MUv6hFIFJPOed4//33CYfDLFy4kC5durB582Yuvvhidu7cSZs2bfwOURKEEoFIPbRgwQJ+/OMf8/nnn9OkSRNGjRpFZmbm2XIlASlPXUMi9cDRo0d59dVXKSgoACLdP5dffjnhcJj9+/fz2muvceedd2rev8SkJSZE6qiysjLeeecdQqEQb775JsXFxbz88sv84z/+o9+hSYLSEhMi9ciJEyfo1asXe/bsoWXLljz44INkZmaSlpbmd2hSBykRiNQBBw8eZMGCBezYsYMZM2bQuHFjHnroIXr37s2wYcNo1KiR3yFKHaZEIJKgSkpKWL58OaFQiOXLl1NaWkpqaionT56kUaNGPP30036HKPWEBotFEohzjrKyMgBefvllRo4cyZ/+9CcmT57Mxx9/TF5env77l1qnFoFIAsjPz+f1118nHA7z5JNPMm7cOB544AGuuuoq7rrrLpKT9VEV7+jdJeKT06dPM3/+fEKhEGvWrME5R79+/WjdujUA7dq1Y/DgwT5HKUGgRCASR6dPn2b79u306tWLBg0a8MILL3D06FGeeuopMjMzueKKK/wOUQJIiUAkDnbs2EE4HGbu3LkcOHCAffv20bRpU95++23at29PgwYarhP/eP7uM7NBZvaZme0wsykxys3MfhUt/9jM+nodk0i85Obmctttt9GjRw+effZZevTowSuvvHJ2pc+OHTsqCYjvPG0RmFkS8DJwF5AP5JnZMufcp+UOGwz0iP7cDMyM3orUOaWlpaxevZouXbpw/fXX07hxYw4fPszzzz/PAw88QOfOnf0OUeQbvO4aSgN2OOc+BzCzbGA4UD4RDAfCLrLWxYdm1sLMOjrnCj2OTaTWfPzxx4RCIebNm8f+/ft5+OGHmTVrFn369GHz5s1a40cSmteJoDOwp9z9fL75336sYzoDf5MIzGwCMAGga9eutR6oyIUaNGgQq1atomHDhgwdOpSsrCyGDBlytlxJQBKd14kg1ieg4ip31TkG59xsYDZEFp2reWgi56+4uJj//M//ZPny5cyZM4cGDRowbNgwhg0bxpgxY7S8s9RJXieCfODScve7AAUXcIyIb5xzfPjhh4TDYbKzszl8+DCdO3dm165ddO/enUmTJvkdokiNeD1dIQ/oYWaXm1kKMAZYVuGYZUBmdPbQLcARjQ9IIjizRPuaNWu49dZbCYVCDB06lNWrV7N79266d+/uc4QitcPTFoFzrtTMJgGrgCRgjnNui5k9Ei2fBawAhgA7gCLge17GJFKV48ePs3jxYkKhEOnp6fzsZz8jIyODUCjEiBEjuOSSS/wOUaTWeX5CmXNuBZEv+/L7ZpXbdsCjXschUpW1a9cyZ84cfv/731NUVET37t0ZNWoUAMnJyX9zmUeR+kZnFktgffHFF1x++eUAzJo1ixUrVvDAAw+QlZXFrbfeqtk+Ehi6VKUEyl/+8heys7MJhUKsW7eOTz/9lKuvvprCwkJatGhB48aN/Q5RxDOVXapS57ZLIOzevZtRo0bRsWNHHn30UU6cOMGLL75Iu3btgMhSD0oCElTqGpJ6yTnHpk2bOH78OLfffjstWrQgLy+PiRMnkpWVRZ8+fdT1IxKlRCD1SmFhIfPmzSMcDvPJJ59w66238sEHH9C8eXN27dqlL/8Ayc2FnBzIyID0dL+jSWxKBFJvTJkyhRdeeIHTp09zyy238Jvf/Ib77rvvbLmSQHDk5sKAAVBSAikpsGaNkkFVNEYgdZJzjg8++ICHH36YgwcPApCamsqUKVPYtm0bubm5TJw4kVatWvkcqfghJyeSBMrKIrc5OX5HlNjUIpA65YsvvmDu3LmEw2F27txJkyZNuOeeexg4cCCjRo06O/dfgi0jI9ISONMiyMjwO6LEpkQgCc85h5lRWFh49lKO/fv356mnnuKee+6hadOmPkcoiSY9PdIdpDGC6lEikIRUVlbGmjVrCIfDOOeYN28eHTt2ZM6cOdx5551ailzOKT1dCaC6lAgkoXz22WfMmTOH119/nYKCAlq0aEFmZubZVsF3v/tdv0MUqXc0WCy+O3jwICUlJQC88cYbTJs2jb59+7Jo0SIKCwuZMWOGZvxIoOTmwnPPRW7jQUtMiC9KSkpYsWIFoVCI5cuXk52dzciRIzl06BClpaW0b9/e7xBFfOHl1NfKlphQ15DEVVFRET/84Q9ZsGABhw4don379vzzP/8z1113HQCtW7f2OUIRf8Wa+ur1WIcSgXhu7969bNmyhYEDB9K4cWNycnIYMGAAWVlZDBw4kORkvQ0l2MqfBe3H1Fd9AsUTRUVFLFmyhFAoxDvvvEOLFi3Yt28fDRs2ZNOmTSQlJfkdokhCiNUVFO+pr0oEUuvmzp3Lo48+yrFjx+jWrRtTp04lMzOThg0bAigJiJQTqyvoRz+K79RXJQKpsZ07dxIOhxk+fDh9+/alZ8+ejBo1iszMTO644w4aNNDkNJHKJMJZ0EoEckGOHDnCwoULCYVCfPDBB5gZrVq1om/fvtx8883cfPPNfoco9Ux9XU00Ec6C9iwRmNkLwN1ACbAT+J5z7nCM43YBx4AyoDTW1CZJLGVlZWev6nX11Vfz85//nAceeIAuXbr4HZrUU/V9NVG/z4L2skXwR+BHzrlSM3se+BHww0qO7e+cO+hhLFIDn3zyCaFQiLy8PHJyckhKSuKll17iiiuuIDU1VSd7ief8mFIZJJ4lAufc6nJ3PwS0LGQdcuDAAebNm0coFGLTpk0kJyczdOhQjh49SvPmzRkzZozfIUqAJEI/en0Wr1G8B4GVlZQ5YLWZbTCzCZU9gJlNMLP1Zrb+wIEDngQZdCdPnuTYsWMArF27lscee4ykpCR+9atfUVhYyJIlS2jevLnPUUoQnelHf+aZ+tctlAhqtMSEmb0DdIhRNNU5tzR6zFQgFRjpYjyZmXVyzhWYWTsi3Un/5Jx7t6rn1RITtcc5x7p16wiFQmRnZ/P444/z4x//mJMnT7Jjxw569+7td4giUks8WWLCOfftczxpFjAMGBArCUQfoyB6+6WZvQmkAVUmAqkdL7zwAq+++iqfffYZF110ESNGjCAj2uZu1KiRkoBIQHjWNWRmg4gMDv+Dc66okmOamNklZ7aBgcBmr2IKuuPHj7Ny5V976N5//33atWvH7373O/bv38/8+fPp16+fjxGKiB+8nDX0a6AR8MforJIPnXOPmFkn4HfOuSFAe+DNaHkyMN8597aHMQXO6dOnycnJIRQKsXjxYr7++mt27dpFt27dWLRoESkpKX6HKCI+83LW0JWV7C8AhkS3Pwf+zqsYgi43N5cxY8bwf//3fzRr1oyxY8eSlZV19upeSgIiAjqzuF756quvyM7OpmvXrgwdOpQrr7ySa6+9lueff57hw4fTuHFjv0MUkQSkRFDHnTp1ilWrVhEKhVi2bBklJSV873vfY+jQobRt25bly5f7HaKIJDglgjpu2LBhrF69mjZt2jBx4kQyMzO54YYb/A5LROoQJYI6ZN++fcyfP5+FCxeyevVqmjVrxuTJk3n00UcZPHjw2WWeRUTOhxJBgisuLmbZsmWEQiFWrVpFWVkZaWlp7N27l2bNmjFkyBC/QxSROk6JIAE55zh27BjNmjVj586d3HfffXTp0oV/+7d/IzMzk6uuusrvEEWkHlEiSCC7du1i7ty5hMNhbrrpJubPn0/v3r35n//5H9LS0nRlLxHxhBJBAli8eDH/8R//wdq1awHo378/w4YNO1uerhW2RMRDSgQ+KCsrIycnh29961skJyezbt069u7dyzPPPMP48ePp1q2b3yGKSIDUaPVRv9TV1Ue3bt1KKBTi9ddfZ+/evaxcuZJBgwZx4sQJLrroIl3gRUQ85cnqo1I9BQUFfOc73yEvL4+kpCQGDRrE9OnTz670qTN+RcRPSgQeKCkpYeXKlRw9epTx48fTvn17WrVqxbRp07j//vvp0CHWJRxERPyhRFBLnHNs3LiRUCjEggULOHjwIH369GHcuHEkJSXx9ttaVFVEElO8LlVZ702ZMoXU1FReeeUV+vfvz1tvvUVeXp76/UUk4alFcAGKiopYunQpoVCIX/ziF1x//fXcc889dO/enXvvvZeWLVv6HaIETG4u5ORELuqu2cZyvpQIqsk5x3vvvUc4HGbhwoUcO3aMrl27UlBQwPXXX09aWhppaWl+hykBlJsLAwZASQmkpOji7nL+lAjOoaioiIsvvpivv/6awYMHY2aMHj2azMxMvvWtb9GggXrXxF85OZEkUFYWuc3JUSKQ86NEEMORI0dYtGgRoVCIr7/+mo0bN9K0aVNWrVrFDTfcQJMmTfwOUeSsjIxIS+BMiyA6K1mk2pQIylm3bh3Tp09nyZIlFBcX06tXL7KysigtLSU5OVkXdpeElJ4e6Q7SGIFcKM8SgZn9BPh/wIHoriedcytiHDcImAEkEbmo/c+9iimWzZs307FjR1q3bs3WrVtZtWoVDz74IJmZmaSlpWnWj9QJ6elKANWhQfXYPFtiIpoIjjvnXqzimCTgz8BdQD6QB4x1zn1a1WPXdImJAwcOsGDBAkKhEBs3buSll17iscce4+TJkwA0atTogh9bRBKTBtUrX2LC75HONGCHc+5z51wJkA0M9+rJSktLGTFiBJ06dWLy5MkAzJgxg3HjxgGRBKAkIFI/xRpUlwivxwgmmVkmsB74F+fcVxXKOwN7yt3PB26O9UBmNgGYANC1a9cLCiY5OZkmTZrwgx/8gKysLK699toLehwRqXs0qF65GnUNmdk7QKyFc6YCHwIHAQc8A3R0zj1Y4fdHA3/vnHsoen88kOac+6eqnreurj4qIv4K+hiBJ6uPOue+Xc0n/y3wVoyifODScve7AAU1iUlEpDIaVI/NszECM+tY7u4IYHOMw/KAHmZ2uZmlAGOAZV7FJCIi3+TlGMEvzKwPka6hXcDDAGbWicg00SHOuVIzmwSsIjJ9dI5zbouHMYmISAWeJQLn3PhK9hcAQ8rdXwF84/wCERGJD7+nj4qIiM+UCEREAk6JQEQk4JQIREQCTolARCTglAhERAJOiUBEJOCUCEREAk6JQEQk4JQIREQCTolARCTglAhERAJOiUBEJOCUCEREAk6JQEQk4JQIREQCTolAfJWbC889F7kVEX94ealKkSrl5sKAAVBSAikpsGaNLiwu4ge1CMQ3OTmRJFBWFrnNyfE7IpFg8qxFYGZvAL2id1sAh51zfWIctws4BpQBpc65VK9iksSSkRFpCZxpEWRk+B2RSDB5efH6+85sm9k04EgVh/d3zh30KhZJTOnpke6gnJxIElC3kIg/PB8jMDMD7gXu9Pq5pO5JT1cCEPFbPMYIbgf2O+e2V1LugNVmtsHMJlT2IGY2wczWm9n6AwcOeBKoiEgQ1ahFYGbvAB1iFE11zi2Nbo8FFlTxMLc55wrMrB3wRzPb5px7t+JBzrnZwGyA1NRUV5O4RUTkr2qUCJxz366q3MySgZHAjVU8RkH09kszexNIA76RCERExBtedw19G9jmnMuPVWhmTczskjPbwEBgs8cxiYhIOV4ngjFU6BYys05mtiJ6tz3wvpl9BKwDljvn3vY4JhERKcfTWUPOue/G2FcADIlufw78nZcxiIhI1XRmsYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwCkRiEig5ObCc89FbiXC84vXi4gkitxcGDAASkogJQXWrIH0dL+j8p9aBCISGDk5kSRQVha5zcnxO6LEoEQg9Yqa/VKVjIxISyApKXKbkeF3RIlBXUNSb6jZL+eSnh55X+TkRJKA3h8RSgRSb8Rq9uuDLhWlp+t9UVGNuobMbLSZbTGz02aWWqHsR2a2w8w+M7O/r+T3W5nZH81se/S2ZU3ikWBTs1/kwtR0jGAzMBJ4t/xOM7sGGAP0BgYBvzGzpBi/PwVY45zrAayJ3he5IGea/c88o24hkfNRo64h59xWADOrWDQcyHbOnQS+MLMdQBpQcQhvOJAR3Q4BOcAPaxKTBJua/SLnz6tZQ52BPeXu50f3VdTeOVcIEL1t51E8IiJSiXO2CMzsHaBDjKKpzrmllf1ajH3ufAKLEccEYAJA165da/JQIiJSzjkTgXPu2xfwuPnApeXudwEKYhy338w6OucKzawj8GUVccwGZgOkpqbWKKmIiMhfedU1tAwYY2aNzOxyoAewrpLjsqLbWUBlLQwREfFITaePjjCzfCAdWG5mqwCcc1uAhcCnwNvAo865sujv/K7cVNOfA3eZ2Xbgruh9ERGJI3Ou7vWypKamuvXr1/sdhohInWJmG5xzqd/YXxcTgZkdAHZf4K+3AQ7WYji1RXGdH8V1fhTX+UnUuKBmsXVzzrWtuLNOJoKaMLP1sTKi3xTX+VFc50dxnZ9EjQu8iU2rj4qIBJwSgYhIwAUxEcz2O4BKKK7zo7jOj+I6P4kaF3gQW+DGCERE5G8FsUUgIiLlKBGIiARcvUwEdeGCOWb2hpltiv7sMrNNlRy3y8w+iR7n+Vl0ZvYTM9tbLrYhlRw3KFqHO8zM8+tImNkLZrbNzD42szfNrEUlx8Wlvs7191vEr6LlH5tZX69iKfecl5rZf5vZ1uj7f3KMYzLM7Ei51/dpr+OKPm+Vr4tP9dWrXD1sMrOjZvaDCsfEpb7MbI6ZfWlmm8vtq9b3UK18Fp1z9e4HuBroReT6Bqnl9l8DfAQ0Ai4HdgJJMX7/F8CU6PYU4HmP450GPF1J2S6gTRzr7ifAv57jmKRo3XUHUqJ1eo3HcQ0EkqPbz1f2msSjvqrz9wNDgJVEVuK9BfhTHF67jkDf6PYlwJ9jxJUBvBWv91N1Xxc/6ivGa7qPyAlXca8v4A6gL7C53L5zfg/V1mexXrYInHNbnXOfxSg6e8Ec59wXwJkL5sQ6LhTdDgHf8SRQIv8JAfcCC7x6Dg+kATucc58750qAbCJ15hnn3GrnXGn07odEVrT1S3X+/uFA2EV8CLSIrrDrGedcoXNuY3T7GLCV2NcBSURxr68KBgA7nXMXumJBjTjn3gX+UmF3db6HauWzWC8TQRUS8YI5twP7nXPbKyl3wGoz2xC9JkM8TIo2z+dU0hytbj165UEi/z3GEo/6qs7f72sdmdllwA3An2IUp5vZR2a20sx6xymkc70ufr+nxlD5P2N+1BdU73uoVuqtRpeq9JMlyAVzqlLNGMdSdWvgNudcgZm1A/5oZtui/z14EhcwE3iGSL08Q6Tb6sGKDxHjd2tcj9WpLzObCpQC8yp5mFqvr1ihxthX8e+P63vtb57YrCmwGPiBc+5oheKNRLo/jkfHf5YQWSbea+d6XfysrxTgH4AfxSj2q76qq1bqrc4mApcgF8ypSYxmlgyMBG6s4jEKordfmtmbRJqCNfpiq27dmdlvgbdiFFW3Hms1LjPLAoYBA1y0gzTGY9R6fcVQnb/fkzo6FzNrSCQJzHPO/aFiefnE4JxbYWa/MbM2zjlPF1irxuviS31FDQY2Ouf2Vyzwq76iqvM9VCv1FrSuoUS7YM63gW3OufxYhWbWxMwuObNNZMB0c6xja0uFftkRlTxfHtDDzC6P/jc1hkideRnXIOCHwD8454oqOSZe9VWdv38ZkBmdDXMLcORMM98r0fGmV4GtzrmXKjmmQ/Q4zCyNyHfAIY/jqs7rEvf6KqfSVrkf9VVOdb6Hauez6PVouB8/RL7A8oGTwH5gVbmyqURG2T8DBpfb/zuiM4yA1sAaYHv0tpVHcb4GPFJhXydgRXS7O5FZAB8BW4h0kXhdd3OBT4CPo2+ojhXjit4fQmRWys44xbWDSF/opujPLD/rK9bfDzxy5vUk0mR/OVr+CeVmr3kYUz8i3QIfl6unIRXimhStm4+IDLrfGoe4Yr4uftdX9HkvJvLF3rzcvrjXF5FEVAicin53fb+y7yEvPotaYkJEJOCC1jUkIiIVKBGIiAScEoGISMApEYiIBJwSgYhIwCkRiIgEnBKBiEjA/X8ORmZCA6H7OgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create array with 100 evenly distributed values between -10 and 10\n",
    "x1Line = np.linspace(-10,10,100)\n",
    "\n",
    "#compute x2 values for these points based on the above equation\n",
    "x2Line = -w[0]/w[1]*x1Line-b\n",
    "\n",
    "#plot data points and line defined by the SLP\n",
    "plt.plot(x[0,1:10],x[1,1:10],'.b')\n",
    "plt.plot(x[0,10:],x[1,10:],'.r')\n",
    "plt.plot(x1Line,x2Line,'--k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4fe43c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "In the above example, the SLP successfully classified the points since the provided weights and bias represented a line dividing the two sets of points given. However, in a general case, the weights and bias are not given and should be learned from the data. In general, the process of learning from data is also termed **training** and is a critical part of any machine learning method. As will be illustrated below, training often involves improving some initial values, based on some measure of the error of the predictions made using these values.\n",
    "\n",
    "SLPs can be trained using a method called the delta rule. Next the rule is described, after some essential introduction and derivations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d1208",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Error\n",
    "\n",
    "Consider a SLP as in the previous example. Also, assume that some training data is available in the form of data points $\\mathbf{x}_i$ and labels $y^*_i$.\n",
    "\n",
    "Then, we can initialise the SLP with some arbitrary weights $w_i$ and bias $b$, make a prediction predictions $y_i$ and compute the error between the predictions and the actual labels. There are several ways of defining this error, but for now, let's consider the simple expression):\n",
    "\n",
    "$$E = \\dfrac{1}{2} \\Sigma_{i=1}^{m}\\left( y^*_i - y_i \\right)^2$$\n",
    "\n",
    "where $m$ is the number of available data points/ labels.\n",
    "\n",
    "Ideally, we would like to find the set of weights and bias that minimise this error. Since the weights and bias are the unknowns in this case, the problem is reduced to finding the minimum of a multivariate function. Within this setting, the function to be minimised is also termed **objective** or **loss** function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8212b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multivariate optimisation/ the gradient descent method\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/gradient_descent.png\" width=\"900\" align=\"center\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebdb84a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For univariate functions, minima or maxima occur at **critical** or **stationary** points, i.e. points where the function's derivative is equal to zero. However, it should be noted that stationary points are not necessarily minima. Moreover, minima and maxima can be local, i.e. the points with the smallest or largest value in their neighbohood, or global, i.e. the points with the absolute smallest or largest value of the function.\n",
    "\n",
    "For multivariate functions, critical points are points where the function's gradient is equal to zero. For bivariate functions, the gradient is defined as:\n",
    "\n",
    "$$\\nabla f \\left( x_1, x_2 \\right) = \\dfrac{\\partial f}{\\partial x_1} \\mathbf{e}_1 + \\dfrac{\\partial f}{\\partial x_2} \\mathbf{e}_2$$\n",
    "\n",
    "where $\\mathbf{e}_1,\\mathbf{e}_2$ are the unit vectors in the directions $x_1$ and $x_2$ respectively. The definition is similar for the higher dimenional case.\n",
    "\n",
    "A commonly used method for minimising multivariate functions is the gradient descent method, which, given an initial point $\\mathbf{x}^i$ provides an updated estimate of the minimum as:\n",
    "\n",
    "$$\\mathbf{x}^{i+1} = \\mathbf{x}^{i} - \\epsilon \\nabla f \\left( \\mathbf{x}^{i} \\right)$$\n",
    "\n",
    "where $\\epsilon$ is a positive scalar, termed **learning rate**, which can be determined in various ways. In our case, we will assume it is assigned a constant, small value, e.g. $0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f3be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To gain some further insight on how moving in the direction of the gradient, as described above, will eventually lead to a local minimum, consider a bivariate function as shown in the figure:\n",
    "\n",
    "* It's gradient is a vector, pointing towards the direction in which the function increases the fastest.\n",
    "* It is relatively easy to show that, moving at the oposite direction of the gradient will decrease the function the fastest.\n",
    "* Successive steps along this direction can eventually lead to the minimum of the function.\n",
    "\n",
    "The gradient descent method belongs to a wider range of methods, utilising gradients to optimise multivariate functions, which can be collectively refered to as **gradient based optimisation** methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e8183",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Delta rule\n",
    "\n",
    "##### Gradient of the error\n",
    "\n",
    "The delta rule ban be derived by simply applying the gradient descent method to the error defined above. The partial derivatives of the error with respect to the weights can be derived using the chain rule:\n",
    "\n",
    "$$\\dfrac{\\partial E}{\\partial w_j} = -\\Sigma_{i=1}^{m}\\left( y^*_i - y_i \\right) \\dfrac{\\partial y_i}{\\partial w_j}$$\n",
    "\n",
    "For a SLP, the derivative of the output with respect to the weights is:\n",
    "\n",
    "$$\\dfrac{\\partial y_i}{\\partial w_j} = \\dfrac{\\partial f\\left( \\Sigma w_k x_k + b \\right)}{\\partial w_j} $$\n",
    "\n",
    "where $f$ is the activation function used.\n",
    "\n",
    "Setting $h = \\Sigma w_k x_k + b$ and using the chain rule:\n",
    "\n",
    "$$\\dfrac{\\partial y_i}{\\partial w_j} = f^{\\prime}\\left( h \\right) \\dfrac{\\partial h}{\\partial w_j} $$\n",
    "\n",
    "where $f^{\\prime}\\left( h \\right)$ is the derivative of the activation function evaluated for the current weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b23f5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Also, the derivative of $h$ can be obtained as:\n",
    "\n",
    "$$\\dfrac{\\partial h}{\\partial w_j} = \\dfrac{\\partial \\Sigma w_k x_k + b}{\\partial w_j} = x_j$$\n",
    "\n",
    "Substituting in the initial expression:\n",
    "\n",
    "$$\\dfrac{\\partial y_i}{\\partial w_j} = f^{\\prime}\\left( h \\right) x_j = f^{\\prime}\\left( \\Sigma w_k x_k + b \\right) x_j$$\n",
    "\n",
    "Then, the expression for the partial derivative of the error becomes:\n",
    "\n",
    "$$\\dfrac{\\partial E}{\\partial w_j} = - \\Sigma_{i=1}^{m}\\left( y^*_i - y_i \\right) f^{\\prime}\\left( \\Sigma w_k x_k + b \\right) x_j$$\n",
    "\n",
    "The partial derivative with respect to the bias can be obtained in a similar way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9315db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Expressions for updating the weights and bias\n",
    "\n",
    "Using the above, the final rule for updating the weights can be obtained as:\n",
    "\n",
    "$$w_j^{k+1} = w_j^{k} + \\epsilon \\Sigma_{i=1}^{m}\\left( y^*_i - y_i \\right) f^{\\prime} x_j$$\n",
    "\n",
    "where $w_j^{k}$ and $w_j^{k+1}$ are the current and updated estimate of the weights. In vector form, the expression can be rewritten as:\n",
    "\n",
    "$$\\mathbf{w}^{k+1} = \\mathbf{w}^{k} + \\epsilon \\Sigma_{i=1}^{m}\\left( y^*_i - y_i \\right) f^{\\prime} \\mathbf{x}$$\n",
    "\n",
    "\n",
    "Similarly, an expression for the bias can be derived: \n",
    "\n",
    "$$b^{k+1} = b^{k+1} + \\epsilon \\Sigma_{i=1}^{m}\\left( y^*_i - y_i \\right) f^{\\prime}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f418f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that in the above expression, the derivative of the activation function is required. For all commonly used activation functions, derivatives can be computed analytically, allowing to easily implement gradient based optimisation methods. This is a very important feature of neural networks, which is partially responsible for their success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f53e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moreover, in the general case, multiple iterations might be necessary, which can be performed with all or parts of the available data, termed **batches**. For example, half of the data might be used to update the weights during the first iteration, the other half during the second, then again the first half during the third etc. Every iteration or set of iterations during which all of the data is used, is called an **epoch**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43211819",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "Let's illustrate the training process for a SLP using the example introduced above.\n",
    "\n",
    "To facilitate the process, we can define functions for the sigmoid and it's derivative, given as:\n",
    "\n",
    "$$ f\\left( x \\right)=\\frac{1}{1+e^{-a x}} $$\n",
    "$$ f^\\prime\\left( x \\right)= f\\left( x \\right) \\left[1-f\\left( x \\right) \\right] $$\n",
    "\n",
    "These can be defined in python as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea13514-b305-4621-91c0-fe70efa645b1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    '''Function implementing a sigmoid activation function using numpy. \n",
    "       x is assumed to be a numpy array and the output argument will be a numpy array of the same size'''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    '''Function implementing the derivative of a sigmoid activation function using numpy. \n",
    "       x is assumed to be a numpy array and the output argument will be a numpy array of the same size'''\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c3f92-dd06-4944-8a13-5cced7467c30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, we will initialise the SLP with zero weights and bias and apply the delta rule once to improve these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f3270",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy\n",
    "\n",
    "epsilon=0.01 #learning rate\n",
    "m = len(labels) #number of training data points\n",
    "\n",
    "#initial weights and bias\n",
    "wt = np.array([0.,0.])\n",
    "bt = 0\n",
    "\n",
    "#Evaluate the SLP expression to obtain an initial prediction\n",
    "y = sigmoid((np.matmul(x.transpose(),wt)+bt))\n",
    "\n",
    "#Compute and print error of initial prediction\n",
    "E = 0.5*((labels-y)**2).sum()\n",
    "\n",
    "print('Initial error: ', E)\n",
    "\n",
    "#Update weights and bias using the delta rule\n",
    "#compute derivative of activation function\n",
    "activationDerivative = sigmoidDerivative((np.matmul(x.transpose(),wt)+bt))\n",
    "\n",
    "#loop training data points and update weights and bias\n",
    "for i in range(m):\n",
    "    wt+=epsilon*(labels[i]-y[i])*activationDerivative[i]*x[:,i].transpose()\n",
    "    bt+=epsilon*(labels[i]-y[i])*activationDerivative[i]\n",
    "\n",
    "#prediction using updated weights\n",
    "y = sigmoid(np.matmul(x.transpose(),wt)+bt)\n",
    "\n",
    "#new error\n",
    "E = 0.5*((labels-y)**2).sum()\n",
    "\n",
    "#print error, weights, bias and predictions\n",
    "print('Updated error:', E)\n",
    "print('Updated weights: ', wt)\n",
    "print('Updated bias: ', bt)\n",
    "print('Updated predictions:', y>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc5ded-04f7-477c-962e-a12c0cd32924",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The new weights obtained are different that the ones used above, however they lead to correct predictions.\n",
    "\n",
    "To gain some insight, the line obtained after training can be plotted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ab766",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#create array with 100 evenly distributed values between -10 and 10\n",
    "x1Linet = np.linspace(-10,10,100)\n",
    "\n",
    "#compute x2 values for these points based on the above equation\n",
    "x2Linet = -wt[0]/wt[1]*x1Linet-bt\n",
    "\n",
    "#plot data points, line used in first example, and line obtained after training\n",
    "plt.plot(x[0,1:10],x[1,1:10],'.b')\n",
    "plt.plot(x[0,10:],x[1,10:],'.r')\n",
    "plt.plot(x1Line,x2Line,'--k',label='Actual line')\n",
    "plt.plot(x1Linet,x2Linet,'--g',label='Line after training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab79d83-a944-4a83-b444-287612f2b933",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The line obtained after training correctly divides the training data into two classes.\n",
    "\n",
    "In the above example, good results were obtained after just one epoch. However, this is not the case in general and very often the accuracy of results depends on the initial values used for the weights.\n",
    "\n",
    "In the next cell, different values are used for the initial weights, requiring a larger number of epochs to obtain good results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2a3ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy\n",
    "\n",
    "epsilon=0.01 #learning rate\n",
    "m = len(labels) #number of training data points\n",
    "\n",
    "#initial weights and bias\n",
    "wt2 = np.array([1.,0.])\n",
    "bt2 = 0\n",
    "\n",
    "#Evaluate the SLP expression to obtain an initial prediction\n",
    "y = sigmoid(np.matmul(x.transpose(),wt2)+bt2)\n",
    "\n",
    "#Compute and print error of initial prediction\n",
    "E = 0.5*((labels-y)**2).sum()\n",
    "\n",
    "print('Initial error: ', E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17481d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Update weights and bias using the delta rule\n",
    "#a loop is added to repeat the update for 10 epochs\n",
    "for epoch in range(10):\n",
    "    #compute derivative of activation function\n",
    "    activationDerivative = sigmoidDerivative((np.matmul(x.transpose(),wt)+bt))\n",
    "\n",
    "    #loop training data points and update weights and bias\n",
    "    for i in range(m):\n",
    "        wt2+=epsilon*(labels[i]-y[i])*activationDerivative[i]*x[:,i].transpose()\n",
    "        bt2+=epsilon*(labels[i]-y[i])*activationDerivative[i]\n",
    "\n",
    "    #prediction using updated weights\n",
    "    y = sigmoid(np.matmul(x.transpose(),wt2)+bt2)\n",
    "\n",
    "    #new error\n",
    "    E = 0.5*((labels-y)**2).sum()\n",
    "\n",
    "    #print error, weights, bias and predictions\n",
    "    print('Epoch: ', epoch+1, ', error: ' , E)\n",
    "    \n",
    "print('Updated weights: ', wt2)\n",
    "print('Updated bias: ', bt2)\n",
    "print('Updated predictions:', y>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889ac55-fe5f-4e98-9718-8796a9448799",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The line corresponding to the new weights and bias can also be plotted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0cf03",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#create array with 100 evenly distributed values between -10 and 10\n",
    "x1Linet2 = np.linspace(-10,10,100)\n",
    "\n",
    "#compute x2 values for these points based on the above equation\n",
    "x2Linet2 = -wt2[0]/wt2[1]*x1Linet2-bt2\n",
    "\n",
    "#plot data points, line used in first example, and line obtained after training\n",
    "plt.plot(x[0,1:10],x[1,1:10],'.b')\n",
    "plt.plot(x[0,10:],x[1,10:],'.r')\n",
    "plt.plot(x1Line,x2Line,'--k',label='Actual line')\n",
    "plt.plot(x1Linet2,x2Linet2,'--g',label='Line after training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234fc08-9d0c-446e-9688-3f2a656dad0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"./Figures/non_linearly_separable.png\" width=\"1000\" align=\"center\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d4054",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As shown, the SLP classifies data by essentialy drawing a line or plane between two sets of points. This means that it can successfully classify only data that can be separated by such a line or plane. Such data is termed **linearly separable** and describes only a small number of problems. For instance, the full Iris dataset, part of which is used for today's problem, includes three classes, the first two, included in our dataset, are linearly separable, however the third one is not. Therefore the applicability of the SLP is rather limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf0e66",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Training with `Tensor Flow` and `Keras`\n",
    "\n",
    "While the code provided above is useful for gaining some insight regarding the inner workings of a SLP, realistic problems require more sophisticated algorithms, as well as a series of features which can be very challenging to implement efficiently. Thus, most of the time, libraries, where these features have already been implemented, are used to train and deploy neural networks. [`Tensor FLow`](https://www.tensorflow.org/) is one of the most widely used libraries for machine learning in general and neural networks in particular. It offers a selection of state of the art algorithms, along with several other features. `Keras` is a high level interface for `Tensor Flow`, which allows to very quickly create and train neural networks. Detailed documentatiom of the package can be found in the [`keras` website](https://keras.io/). Next, the process of defining and training the simple SLP used above, in `Keras` is described."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35140326",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The first step is to import `tensorflow`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055804df-435b-4f5a-9118-8208d1dcc72e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #import tensorflow using an alias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35a9dc-d015-44c5-b094-7dac3cc6ee81",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For our purposes, the simplest type of model used by `keras` can be used, which is termed [`sequential`](https://keras.io/guides/sequential_model/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21d79de-b11b-4b23-b272-8ec1cd4025e1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential() #create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb33334-d662-4974-877a-b805579ec243",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, we can add layers to our model. Since we want to implement a SLP, one layer is enough. When the layer is created, we have to specify the size of the layer's output, also termed number of units, while the number of inputs is set automatically.\n",
    "\n",
    "Several other options can be specified for each layer, as described [here](https://keras.io/api/layers/core_layers/dense/). In our case we will just consider the following:\n",
    "\n",
    "+ We will set the `activation` option to 'sigmoid'. This means that a sigmoid activation function will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c8f37-e3d1-4973-8a7d-37520945e58b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(1, #add a dense layer with 1 unit to the model\n",
    "                                activation = 'sigmoid' #use a sigmoid activation function\n",
    "                               ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbdf19-543a-4677-bd67-db8fa08f335e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Once the layers (or layer in our case!) have been defined, the model can be compiled. At this stage, more options are [available](https://keras.io/api/models/model_training_apis/). More importantly:\n",
    "\n",
    "* The algorithm used to minimise the loss function can be selected. A common choice is the Adam algorithm, which while sharing some common features with the Gradient descent method described above, offers several improvements. A more complete list of the available optimisers can be found in the [`keras` documentation](https://keras.io/api/optimizers/).\n",
    "* The loss function definition can also be selected. For this specific problem, we will use the 'BinaryCrossentropy' option, which employs a function suitable for binary classification. More options can be found in the [`keras` documentation](https://keras.io/api/losses/)\n",
    "* Finally, different metric for estimating the accuracy of the computed results can be selected. In our case we will use 'Accuracy', which represents the frequency by which predictions equal labels, for instance a value of 1.0, means all of the predictions are equal to the labels. All options can be found in the [`keras` documentation](https://keras.io/api/metrics/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469194e-4590-452f-8e1b-7bf18240a1d5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer='adam', #use the Adam optimiser\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), #use binary cross entropy as a loss function\n",
    "              metrics=['accuracy']) #use accuracy as a metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cfd234-e168-43d4-8521-5c7511a78d57",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Finally, the model can be trained using the [`fit` method](https://keras.io/api/models/model_training_apis/#fit-method). The following arguments need to be provided:\n",
    "\n",
    "+ **Input data**: this includes our training data points as a `numpy` array. It should be noted that, `keras` expectes the first direction of this matrix to correspond to different inputs and the second one to correspond to different data points. Therefore data might need to be modified accordingly.\n",
    "+ **Target data**: This includes our labels as a `numpy` array.\n",
    "\n",
    "More optional arguments can also be provided. For now we will only set the number of epochs, trying values 10 and 100. Notice that different numbers or epochs, or even different runs with the same number of epochs yield different results. This is a consequence of the weights and bias of the SLP being initialised with random numbers, which change for every run. For now, we will repeat the training a few times, until we can get good results in terms of accuracy. In the future, we will explore more advanced training strategies that will allow us to obtain more consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7437791",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Try re-running the cell a few times, until a good accuracy can be obtained. \n",
    "#Also try changing the number of epochs to 10\n",
    "model.fit(x.transpose(), labels, epochs=100) # train model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655b5e6-ee92-4dfe-bee7-e7c76bb1dd82",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Using the model to make predictions\n",
    "\n",
    "Once the model has been trained, it can be used to make predictions. This can be done using the `predict` method of the `model` class in `keras`, which receives as input a `numpy` array with new data points. In our case, we will test the method with the existing data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69cb31-c3ae-41dd-a7f7-536f9157049a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#use predict method to obtain the predicted labels for the points used for training\n",
    "#a 0.5 threshold is used to convert the values to binary format\n",
    "yPred = model.predict(x.transpose())>0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f95cb0-ff10-45e2-8af4-a372c8a33ffa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Visualising results\n",
    "\n",
    "For classification problems, a useful way of visualising results is through a confusion matrices. In these matrices:\n",
    "\n",
    "* Rows represent true or actual classes.\n",
    "* Columns represent predicted classes.\n",
    "* Element $ij$ represents the number of data points whose actual class was cass $i$ and whose predicted class was class $j$. For example:\n",
    "    + if the entry in the 1st row and 2nd column is 5, this means that 5 elements that belong to class 1 were classified as belonging to class 2\n",
    "    + if the entry in the 1st row and 1st column is 10, this means that 10 elements that belong to class 1 were correctly classified as belonging to class 1. \n",
    "  \n",
    "  Therefore, diagonal entries of the matrix represent correctly classified data points and off diagonal entries missclassified ones. Ideally, we would like to obtain a classification matrix with zero off diagonal entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5c84c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To produce such matrices in our case, we will employ the `confusion_matrix` function and `ConfusionMatrixDisplay` class from the `sklearn module`.\n",
    "\n",
    "First we need to import these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fcfb4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b84a53-c076-47f1-890b-06420537e056",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Next we can create a confusion matrix using the `confusion_matrix` function. As input, we need to provide the labels predicted by our model, as well as the true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dc490-fe07-48e0-af8f-8cbafe1a7b62",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "confusionMatrix=confusion_matrix(labels,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19efff52-7a58-42ef-b56f-0c2463869324",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Finally, the matrix can be plotted using the `ConfusionMatrixDisplay` class, which takes as input the confusion matrix created previously. For nicer visualisation, we will provide an additional optional argument, in the form of a list containing the class names. These will be plotted as labels for the confusion matrix rows and columns.\n",
    "\n",
    "Once the object is created, it can be plotted using the `plot` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63584d-2e2f-4701-8da1-e9401e67a603",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "classLabels = ['above','below']\n",
    "\n",
    "confusionMatrixPlot = ConfusionMatrixDisplay(confusion_matrix=confusionMatrix, display_labels=classLabels)\n",
    "\n",
    "confusionMatrixPlot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60763a3b-51d0-4eb9-8839-f64d9f095c48",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Examining the trained SLP\n",
    "\n",
    "The weights and bias of the model trained with `keras` can be accessed through the `get_layer` method of the model and the `weights` attribute of the layer object as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f28d21",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tfWeights = model.get_layer(index=0).weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37964390-3d86-495c-a163-5b4f27ac640e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The resulting object is a list containing both the weights and bias. Individual values can be accessed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b284c3-20e2-4db8-af40-c8e89ed4e4c1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "wt3 = np.array([float(tfWeights[0][0]),float(tfWeights[0][1])])\n",
    "bt3 = float(tfWeights[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa959d-029b-4a68-8307-baaa3216935c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Then, the line represented by the SLP can be plotted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4a148-8ebb-4fef-bd31-67e3d2ae3371",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x1Linet3 = np.linspace(-10,10,100)\n",
    "x2Linet3 = -wt3[0]/wt3[1]*x1Linet3-bt3\n",
    "\n",
    "plt.plot(x[0,1:10],x[1,1:10],'.b')\n",
    "plt.plot(x[0,10:],x[1,10:],'.r')\n",
    "plt.plot(x1Line,x2Line,'--k',label='Actual line')\n",
    "plt.plot(x1Linet3,x2Linet3,'--g',label='Line after training with keras')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d66395-19e7-4bb1-a17d-ab543975cfc2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "### Key points\n",
    "\n",
    "In this lecture:\n",
    "\n",
    "+ We introduced some basic machine learning terminology.\n",
    "+ We presented in detail the structure and training process for the simplest neural network architecture, the SLP.\n",
    "+ We introduced `keras` and its use in a simple classification problem.\n",
    "\n",
    "The above should allow us to solve today's problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28258f7d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Resources/Further reading\n",
    "\n",
    "+ [`keras` website](https://keras.io/)\n",
    "+ I. Goodfellow, Y. Bengio and A. Courville. *Deep learning*. MIT press, 2016 (library 006.31 GOO)\n",
    "+ D.W. Patterson. *Artificial Neural Networks: Theory and Applications*. Prentice Hall, 1996 (library 006.3 PAT)\n",
    "+ K. Mehrotra, C.K. Mohan, S. Ranka. *Elements of Artificial neural networks*, MIT Press, 1997 (library 001.535 MEH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b41720",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Solving this week's problem\n",
    "\n",
    "Today's problem is a binary classification problem with linearly separable data points.\n",
    "\n",
    "### Visualising the data\n",
    "\n",
    "To illustrate how variables are linearly separable, and gain some insight into the problem, we will first create a few plots of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc59dc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# extract sepal length and width and petal length and width from pandas data frame\n",
    "sepalLength=irisDf['sepal length']\n",
    "sepalWidth=irisDf['sepal width']\n",
    "petalLength=irisDf['petal length']\n",
    "petalWidth=irisDf['petal width']\n",
    "\n",
    "#create subplots using subplots from pyplot\n",
    "#this will create a plot including 6 subplots arranged in a 2x3 matrix\n",
    "fig, axs = plt.subplots(2, 3,figsize=(18,8))\n",
    "\n",
    "#plot the sepal length vs the sepal width at the first subplot (coordinates 0,0)\n",
    "#the first 50 points (Iris-setosa) are plotted in blue and the remaining 50 'Iris-versicolor' in red\n",
    "axs[0,0].plot(sepalLength[:50],sepalWidth[:50],'.b')\n",
    "axs[0,0].plot(sepalLength[50:],sepalWidth[50:],'.r')\n",
    "axs[0,0].set(xlabel='sepal length',ylabel='sepal width')\n",
    "\n",
    "#plot the sepal length vs the petal lenght at the second subplot (coordinates 0,1)\n",
    "axs[0,1].plot(sepalLength[:50],petalLength[:50],'.b')\n",
    "axs[0,1].plot(sepalLength[50:],petalLength[50:],'.r')\n",
    "axs[0,1].set(xlabel='sepal length',ylabel='petal length')\n",
    "\n",
    "#plot the sepal length vs the petal width at the third subplot (coordinates 0,2)\n",
    "axs[0,2].plot(sepalLength[:50],petalWidth[:50],'.b')\n",
    "axs[0,2].plot(sepalLength[50:],petalWidth[50:],'.r')\n",
    "axs[0,2].set(xlabel='sepal length',ylabel='petal width')\n",
    "\n",
    "#fill the last three subplots similar to the first three\n",
    "axs[1,0].plot(sepalWidth[:50],petalLength[:50],'.b')\n",
    "axs[1,0].plot(sepalWidth[50:],petalLength[50:],'.r')\n",
    "axs[1,0].set(xlabel='sepal width',ylabel='petal length')\n",
    "\n",
    "axs[1,1].plot(sepalWidth[:50],petalWidth[:50],'.b')\n",
    "axs[1,1].plot(sepalWidth[50:],petalWidth[50:],'.r')\n",
    "axs[1,1].set(xlabel='sepal width',ylabel='petal width')\n",
    "\n",
    "axs[1,2].plot(petalLength[:50],petalWidth[:50],'.b')\n",
    "axs[1,2].plot(petalLength[50:],petalWidth[50:],'.r')\n",
    "axs[1,2].set(xlabel='petal length',ylabel='petal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707229b2-00db-4840-91bc-f597764eac36",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "From the above it is clear that the projections of our data points on different planes can be easily separated by lines!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2ef4c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Formatting and normalising the data\n",
    "\n",
    "Before creating and training a `keras` model, we need to extract our data from the pandas data frame and normalise it.\n",
    "\n",
    "The first task can be accomplished by extracting columns of the frame and converting them to `numpy` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d52efc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "irisData=irisDf[['sepal length','sepal width','petal length','petal width']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2834b1-bbe1-4d63-aa3d-dffd44e17560",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Normalisation is an important task when preprocessing data for machine learning. It ensures that consistent results can be obtained regardless of the magnitude of tha numerical values in our data set. In our case, we will divide each of the measurements by the maximum value for that measurement found in our data set, thus ensuring that all values are in the range $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb069a8-fe24-44e9-845b-24f90968338e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "irisData = irisData/irisData.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dc210-2a66-413d-9551-c277ce2172aa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Finally, we will create labels for our data. Since the first 50 entries in our data set correspond to the class 'Iris-setosa' and the last 50 to the class 'Iris-versicolor', the task will simply consist of creating an array with 50 values equal to 0, followed by 50 values equal to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc94f1-389b-4eb9-8883-892bd76c8d53",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "irisLabels = np.zeros(100)\n",
    "irisLabels[50:]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e6303-bef6-486e-b3f7-ff71a01735be",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Creating and training a model with `keras`\n",
    "\n",
    "Next, a model can be created and trained using the data extracted above. Different numbers of training epochs can be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469a355",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "803a34d6-2653-4370-9514-c4df1e68beed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Visualising results\n",
    "\n",
    "Results can be visualised using a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4614d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
